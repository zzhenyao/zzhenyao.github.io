<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.3.0/css/all.min.css" integrity="sha256-/4UQcSmErDzPCMAiuOiWPVVsNN2s3ZY/NsmXNcj0IFc=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"pkunicor.github.io","root":"/","images":"/images","scheme":"Mist","darkmode":false,"version":"8.15.0","exturl":false,"sidebar":{"position":"right","display":"hide","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":true,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="密歇根大学EECS498 计算机视觉 第二章">
<meta property="og:type" content="article">
<meta property="og:title" content="计算机视觉 图像分类">
<meta property="og:url" content="https://pkunicor.github.io/2024/05/06/14-24-17/index.html">
<meta property="og:site_name" content="且听风吟">
<meta property="og:description" content="密歇根大学EECS498 计算机视觉 第二章">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://pkunicor.github.io/2024/05/06/14-24-17/baab9e4b97aceb77ec70abeda6be022d_b.png">
<meta property="og:image" content="https://pkunicor.github.io/2024/05/06/14-24-17/1ee9457872f773d671dd5b225647ef45_b.jpg">
<meta property="og:image" content="https://pkunicor.github.io/2024/05/06/14-24-17/object_detection.jpg">
<meta property="og:image" content="https://pkunicor.github.io/2024/05/06/14-24-17/bbbfd2e6878d6f5d2a82f8239addbbc0_b.jpg">
<meta property="og:image" content="https://pkunicor.github.io/2024/05/06/14-24-17/fff49fd8cec00f77f657a4c4a679b030_b.jpg">
<meta property="og:image" content="https://pkunicor.github.io/2024/05/06/14-24-17/fff49fd8cec00f77f657a4c4a679b030_b.jpg">
<meta property="og:image" content="https://pkunicor.github.io/2024/05/06/14-24-17/95cfe7d9efb83806299c218e0710a6c5_b.jpg">
<meta property="og:image" content="https://pkunicor.github.io/2024/05/06/14-24-17/60.jpg">
<meta property="og:image" content="https://pkunicor.github.io/2024/05/06/14-24-17/60.jpg">
<meta property="og:image" content="https://pkunicor.github.io/2024/05/06/14-24-17/237615075-bdd1fa05-cb3c-4dc5-b24f-940987cdb225.jpg">
<meta property="og:image" content="https://pkunicor.github.io/2024/05/06/14-24-17/6a3ceec60cc0a379b4939c37ee3e89e8_b.png">
<meta property="og:image" content="https://pkunicor.github.io/2024/05/06/14-24-17/cc88207c6c3c5e91df8b6367368f6450_b.jpg">
<meta property="og:image" content="https://pkunicor.github.io/2024/05/06/14-24-17/fd42d369eebdc5d81c89593ec1082e32_b.png">
<meta property="og:image" content="https://pkunicor.github.io/2024/05/06/14-24-17/0f4980edb8710eaba0f3e661b1cbb830_b.jpg">
<meta property="article:published_time" content="2024-05-06T06:24:17.000Z">
<meta property="article:modified_time" content="2024-05-06T07:26:13.747Z">
<meta property="article:author" content="yao">
<meta property="article:tag" content="计算机视觉, 图像处理, 深度学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://pkunicor.github.io/2024/05/06/14-24-17/baab9e4b97aceb77ec70abeda6be022d_b.png">


<link rel="canonical" href="https://pkunicor.github.io/2024/05/06/14-24-17/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://pkunicor.github.io/2024/05/06/14-24-17/","path":"2024/05/06/14-24-17/","title":"计算机视觉 图像分类"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>计算机视觉 图像分类 | 且听风吟</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">且听风吟</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">轻舟过万重,青山依旧在</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%B3%BB%E5%88%97"><span class="nav-number">1.</span> <span class="nav-text">系列</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB"><span class="nav-number"></span> <span class="nav-text">图像分类</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A6%82%E5%BF%B5"><span class="nav-number">1.</span> <span class="nav-text">概念</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%9B%B0%E9%9A%BE%E5%92%8C%E6%8C%91%E6%88%98"><span class="nav-number">2.</span> <span class="nav-text">困难和挑战</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%BB%BB%E5%8A%A1"><span class="nav-number">3.</span> <span class="nav-text">目标检测任务</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E9%A9%B1%E5%8A%A8%E6%96%B9%E6%B3%95"><span class="nav-number">4.</span> <span class="nav-text">数据驱动方法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="nav-number">5.</span> <span class="nav-text">数据集</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#MNIST%E6%95%B0%E6%8D%AE%E9%9B%86%EF%BC%9A%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E4%B8%AD%E7%9A%84%E6%9E%9C%E8%9D%87"><span class="nav-number">5.1.</span> <span class="nav-text">MNIST数据集：计算机视觉中的果蝇</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CIFAR%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="nav-number">5.2.</span> <span class="nav-text">CIFAR数据集</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ImageNet%EF%BC%9A%E9%BB%84%E9%87%91%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="nav-number">5.3.</span> <span class="nav-text">ImageNet：黄金数据集</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Nearest-Neighbor%E5%88%86%E7%B1%BB%E5%99%A8"><span class="nav-number">6.</span> <span class="nav-text">Nearest Neighbor分类器</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#k-Nearest-Neighbor%E5%88%86%E7%B1%BB%E5%99%A8"><span class="nav-number">7.</span> <span class="nav-text">k-Nearest Neighbor分类器</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%94%A8%E4%BA%8E%E8%B6%85%E5%8F%82%E6%95%B0%E8%B0%83%E4%BC%98%E7%9A%84%E9%AA%8C%E8%AF%81%E9%9B%86"><span class="nav-number">8.</span> <span class="nav-text">用于超参数调优的验证集</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Nearest-Neighbor%E5%88%86%E7%B1%BB%E5%99%A8%E7%9A%84%E4%BC%98%E5%8A%A3"><span class="nav-number">9.</span> <span class="nav-text">Nearest Neighbor分类器的优劣</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%B0%8F%E7%BB%93"><span class="nav-number">10.</span> <span class="nav-text">小结</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%B0%8F%E7%BB%93%EF%BC%9A%E5%AE%9E%E9%99%85%E5%BA%94%E7%94%A8k-NN"><span class="nav-number">11.</span> <span class="nav-text">小结：实际应用k-NN</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0"><span class="nav-number"></span> <span class="nav-text">数据集代码实现</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86%E7%B1%BB%E2%80%94%E2%80%94Dataset"><span class="nav-number">1.</span> <span class="nav-text">数据集类——Dataset</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%8B%93%E5%B1%95%E9%98%85%E8%AF%BB"><span class="nav-number">2.</span> <span class="nav-text">拓展阅读</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="yao"
      src="/images/logo.png">
  <p class="site-author-name" itemprop="name">yao</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">118</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">14</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">30</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/PKunicor" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;PKunicor" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
  </div>
  <div class="cc-license animated" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" class="cc-opacity" rel="noopener" target="_blank"><img src="https://cdnjs.cloudflare.com/ajax/libs/creativecommons-vocabulary/2020.11.3/assets/license_badges/small/by_nc_sa.svg" alt="Creative Commons"></a>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://pkunicor.github.io/2024/05/06/14-24-17/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/logo.png">
      <meta itemprop="name" content="yao">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="且听风吟">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="计算机视觉 图像分类 | 且听风吟">
      <meta itemprop="description" content="密歇根大学EECS498 计算机视觉 第二章">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          计算机视觉 图像分类
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2024-05-06 14:24:17 / 修改时间：15:26:13" itemprop="dateCreated datePublished" datetime="2024-05-06T14:24:17+08:00">2024-05-06</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/" itemprop="url" rel="index"><span itemprop="name">计算机视觉</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
</div>



        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
            <div class="post-description">密歇根大学EECS498 计算机视觉 第二章</div>
	<hr>
        <p>更新历史</p>
<ul>
<li>24.05.06：初稿</li>
</ul>
<h2 id="系列"><a href="#系列" class="headerlink" title="系列"></a>系列</h2><ul>
<li><a href="/2024/05/06/10-28-51/" title="eecs498 ML-DL-CV 笔记汇总">计算机视觉-笔记汇总</a>
</li>
</ul>
<h1 id="图像分类"><a href="#图像分类" class="headerlink" title="图像分类"></a>图像分类</h1><h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><p><strong>目标</strong>：这一节我们将介绍图像分类问题。所谓图像分类问题，就是已有固定的分类标签集合，然后对于输入的图像，从分类标签集合中找出一个分类标签，最后把分类标签分配给该输入图像，或者简单的说，就是对于一个给定的图像，预测它属于哪个类别（或者给出属于一系列不同标签的可能性）。虽然看起来挺简单的，但这可是计算机视觉领域的核心问题之一，并且有着各种各样的实际应用。在这里我们面临的挑战就是语义鸿沟。在后面的课程中，我们可以看到计算机视觉领域中很多看似不同的问题（比如物体检测和分割），都可以被归结为图像分类问题。</p>
<p><strong>例子</strong>：以下图为例，图像分类模型读取该图片，并生成该图片属于集合 {cat, dog, hat, mug}中各个标签的概率。需要注意的是，对于计算机来说，图像是一个由数字组成的巨大的3维数组（在深度学习工具中，图像就是一个三维张量）。在下图这个例子中，猫的图像大小是宽248像素，高400像素，有3个颜色通道，分别是红、绿和蓝（简称RGB）。</p>
<p>如此，该图像就包含了248X400X3=297600个数字，每个数字都是在范围0-255之间的整型，其中0表示全黑，255表示全白。我们的任务就是把这些上百万的数字变成一个简单的标签，比如”猫”。或者说，我们需要借助某种方法将这个原始数字网络转变为相应的有意义的语义——比如说“猫”标签</p>
<img src="/2024/05/06/14-24-17/baab9e4b97aceb77ec70abeda6be022d_b.png" class>
<h2 id="困难和挑战"><a href="#困难和挑战" class="headerlink" title="困难和挑战"></a>困难和挑战</h2><p>对于人来说，识别出一个像”猫”一样视觉概念是简单至极的，然而从计算机视觉算法的角度来看就值得深思了。我们在下面列举了计算机视觉算法在图像识别方面遇到的一些困难</p>
<ul>
<li><strong>视角变化（</strong>Viewpoint variation<strong>）</strong>：同一个物体，摄像机可以从多个角度来展现，尽管可能角度的变化很轻微，但是可能使得这些数字发生不直观的某种改变</li>
<li><strong>类内差异（</strong>Intra-class variation<strong>）</strong>：一类物体的个体之间的外形差异很大，比如椅子。这一类物体有许多不同的对象，每个都有自己的外形。比如说猫就是一种很会变形的生物</li>
<li><strong>相似类（</strong>Fine-Grained Categories<strong>）</strong>：不同类物体的个体之间的外形差异小</li>
<li><strong>背景干扰（</strong>Background clutter<strong>）</strong>：物体可能混入背景之中，使之难以被辨认</li>
<li><strong>光照条件（</strong>Illumination conditions<strong>）</strong>：在像素层面上，光照的影响非常大，比如说光照和昏暗情况下图像会有不同情况</li>
<li><strong>形变（</strong>Deformation<strong>）</strong>：很多东西的形状并非一成不变，会有很大变化。</li>
<li><strong>遮挡（</strong>Occlusion<strong>）</strong>：目标物体可能被挡住。有时候只有物体的一小部分（可以小到几个像素）是可见的，比如说猫隐藏在草丛中，并不明显</li>
<li><strong>大小变化（</strong>Scale variation<strong>）</strong>：物体可视的大小通常是会变化的（不仅是在图片中，在真实世界中大小也是变化的）。</li>
</ul>
<p>面对以上所有变化及其组合，好的图像分类模型能够在维持分类结论稳定的同时，保持对类间差异足够敏感。  </p>
<img src="/2024/05/06/14-24-17/1ee9457872f773d671dd5b225647ef45_b.jpg" class>
<h2 id="目标检测任务"><a href="#目标检测任务" class="headerlink" title="目标检测任务"></a>目标检测任务</h2><p>当然，计算机视觉不止有图像分类，还有另一个相关的任务——目标检测，这个任务我们需要将图像中的目标对象圈出来</p>
<p>结果证明，图像分类本来就是一个基础，可以用来构建更多更复杂的应用程序，比如说目标检测等</p>
<img src="/2024/05/06/14-24-17/object_detection.jpg" class>
<p>—————————————————————————————————————————</p>
<p><strong>想法</strong>：如何实现图像分类？</p>
<p>根据之前所了解到的方法，我们可能首先想到通过对照片进行<strong>边缘检测</strong>来提取特征，如何尝试找到角点或者其他类型的可解释模式，比如说猫有三角形尖耳朵，所以可以通过检测这方面的边缘信息，或者我们知道猫有胡须，所以我们可以提取胡须的边缘信息，我们根据这些信息来写一个算法来检测他们</p>
<p>当然，这并不是一个很好的方法，比如说会有没有胡须的猫，会有没有尖耳朵的猫，或者有时候边缘检测器会失效从而无法正常提交所需的边缘，而且这很难进行迁移——当我们可以成功识别猫的时候，如果我们想将其用到其他方面，比如说识别狗，那么之前的工作将毫无意义，所以我们需要找到一种具有可扩展性的算法</p>
<h2 id="数据驱动方法"><a href="#数据驱动方法" class="headerlink" title="数据驱动方法"></a>数据驱动方法</h2><p>如何写一个图像分类的算法呢？这和写个排序算法可是大不一样。怎么写一个从图像中认出猫的算法？搞不清楚。因此，与其在代码中直接写明各类物体到底看起来是什么样的，倒不如说我们采取的方法和教小孩儿看图识物类似：给计算机很多数据，然后实现学习算法，让计算机学习到每个类的外形。这种方法，就是_数据驱动方法_。也就是使用拥有从数据中学习如何识别不同类型对象与图像的算法。既然该方法的第一步就是收集大量已经做好分类标注的图片来作为训练集，那么下面就看看数据集到底长什么样：  </p>
<p>—————————————————————————————————————————</p>
<img src="/2024/05/06/14-24-17/bbbfd2e6878d6f5d2a82f8239addbbc0_b.jpg" class>
<p>这是一个有4个视觉类别的训练集，尽管这个数据集非常简陋。在实际中，我们可能有上千的分类，每个分类都有成千上万的图像。</p>
<p><strong>图像分类流程</strong>。在课程视频中已经学习过，<strong>图像分类</strong>就是输入一个元素为像素值的数组，然后给它分配一个分类标签。完整流程如下：</p>
<ul>
<li><strong>输入</strong>：输入是包含N个图像的集合，每个图像的标签是K种分类标签中的一种。这个集合称为训练集。</li>
<li><strong>学习</strong>：这一步的任务是使用训练集来学习每个类到底长什么样。一般该步骤叫做<strong>训练分类器</strong>或者学习一个模型。</li>
<li><strong>评价</strong>：让分类器来预测它未曾见过的图像的分类标签，并以此来评价分类器的质量。我们会把分类器预测的标签和图像真正的分类标签对比。毫无疑问，如果分类器预测的分类标签和图像真正的分类标签一致，那就是好事，这样的情况越多越好。</li>
</ul>
<h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><h3 id="MNIST数据集：计算机视觉中的果蝇"><a href="#MNIST数据集：计算机视觉中的果蝇" class="headerlink" title="MNIST数据集：计算机视觉中的果蝇"></a>MNIST数据集：计算机视觉中的果蝇</h3><p>MNIST数据集是一种手写数字数据集，其中的每张图片都包括一个不同的手写数字，大小统一为28 $\times$ 28，十个类别，有五万张作为训练集和一万张作为测试集</p>
<p>它更像一种玩具数据集，或者也被称为计算机视觉的果蝇，可以做很多测试，因为这个数据集很小而且简单，可以快速验证新想法</p>
<h3 id="CIFAR数据集"><a href="#CIFAR数据集" class="headerlink" title="CIFAR数据集"></a>CIFAR数据集</h3><p><strong>CIFAR-10</strong>：一个非常流行的图像分类数据集是CIFAR-10。这个数据集包含了60000张32X32的小图像。每张图像都有10种分类标签中的一种。这60000张图像被分为包含50000张图像的训练集和包含10000张图像的测试集。</p>
<p>在下图中你可以看见10个类的10张随机图片。</p>
<img src="/2024/05/06/14-24-17/fff49fd8cec00f77f657a4c4a679b030_b.jpg" class>
<p><strong>左边</strong>：从数据库来的样本图像。<strong>右边</strong>：第一列是测试图像，然后第一列的每个测试图像右边是使用Nearest Neighbor算法，根据像素差异，从训练集中选出的10张最类似的图片。  </p>
<p>此外还有CIFAR100数据集（100类）</p>
<h3 id="ImageNet：黄金数据集"><a href="#ImageNet：黄金数据集" class="headerlink" title="ImageNet：黄金数据集"></a>ImageNet：黄金数据集</h3><p>这是一个非常大的数据，有一千种类别，同时有一百三十万张图片（每个类别1300张），五万张验证集，十万张测试集，性能标准是Top5准确率，图像大小不统一</p>
<h2 id="Nearest-Neighbor分类器"><a href="#Nearest-Neighbor分类器" class="headerlink" title="Nearest Neighbor分类器"></a>Nearest Neighbor分类器</h2><p>作为课程介绍的第一个方法，我们来实现一个<strong>Nearest Neighbor分类器</strong>。虽然这个分类器和卷积神经网络没有任何关系，实际中也极少使用而且其非常简单，但通过实现它，可以让读者对于解决图像分类问题的方法有个基本的认识，也就是机器学习系统的两个基本部分——训练、预测。</p>
<p>其中，训练函数，就是记住所有的数据和标签（或者说进行学习），预测函数，就是预测出图像最可能的标签</p>
<img src="/2024/05/06/14-24-17/fff49fd8cec00f77f657a4c4a679b030_b.jpg" class>
<p>假设现在我们有CIFAR-10的50000张图片（每种分类5000张）作为训练集，我们希望将余下的10000作为测试集并给他们打上标签。Nearest Neighbor算法将会拿着测试图片和训练集中每一张图片去比较，然后将它认为最相似的那个训练集图片的标签赋给这张测试图片。上面右边的图片就展示了这样的结果。请注意上面10个分类中，只有3个是准确的。比如第8行中，马头被分类为一个红色的跑车，原因在于红色跑车的黑色背景非常强烈，所以这匹马就被错误分类为跑车了。</p>
<p>那么具体如何比较两张图片的相似程度呢（或者可以将相似程度理解为距离，距离越近，图片越相似）？在本例中，就是比较32x32x3的像素块。最简单的方法就是逐个像素比较，最后将差异值全部加起来。换句话说，就是将两张图片先转化为两个向量$I_1$和$I_2$，然后计算他们的<strong>L1距离（曼哈顿距离）：</strong></p>
<p>$displaystyle d_1(I_1,I_2)=sum_p|I^p_1-I^p_2|$</p>
<p>这里的求和是针对所有的像素。下面是整个比较流程的图例：  </p>
<img src="/2024/05/06/14-24-17/95cfe7d9efb83806299c218e0710a6c5_b.jpg" class>
<p>以图片中的一个颜色通道为例来进行说明。两张图片使用L1距离来进行比较。逐个像素求差值，然后将所有差值加起来得到一个数值。如果两张图片一模一样，那么L1距离为0，但是如果两张图片很是不同，那L1值将会非常大。</p>
<p>下面，让我们看看如何用代码来实现这个分类器。首先，我们将CIFAR-10的数据加载到内存中，并分成4个数组：训练数据和标签，测试数据和标签。在下面的代码中，<strong>Xtr</strong>（大小是50000x32x32x3）存有训练集中所有的图像，<strong>Ytr</strong>是对应的长度为50000的1维数组，存有图像对应的分类标签（从0到9）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Xtr, Ytr, Xte, Yte = load_CIFAR10(<span class="string">&#x27;data/cifar10/&#x27;</span>) <span class="comment"># a magifunction we provide</span></span><br><span class="line"><span class="comment"># flatten out all images to be one-dimensional</span></span><br><span class="line">Xtr_rows = Xtr.reshape(Xtr.shape[<span class="number">0</span>], <span class="number">32</span> * <span class="number">32</span> * <span class="number">3</span>) <span class="comment"># Xtr_rowbecomes 50000 x 3072</span></span><br><span class="line">Xte_rows = Xte.reshape(Xte.shape[<span class="number">0</span>], <span class="number">32</span> * <span class="number">32</span> * <span class="number">3</span>) <span class="comment"># Xte_rowbecomes 10000 x 3072</span></span><br></pre></td></tr></table></figure>
<p>现在我们得到所有的图像数据，并且把他们拉长成为行向量了。接下来展示如何训练并评价一个分类器：  </p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">    nn = NearestNeighbor() <span class="comment"># create a Nearest Neighbor classifier class</span></span><br><span class="line">​    nn.train(Xtr_rows, Ytr) <span class="comment"># train the classifier on the training images and labels</span></span><br><span class="line">​    Yte_predict = nn.predict(Xte_rows) <span class="comment"># predict labels on the test images</span></span><br><span class="line">​    <span class="comment"># and now print the classification accuracy, which is the average number</span></span><br><span class="line">​    <span class="comment"># of examples that are correctly predicted (i.e. label matches)</span></span><br><span class="line">​    <span class="built_in">print</span> <span class="string">&#x27;accuracy: %f&#x27;</span> % ( np.mean(Yte_predict == Yte) )</span><br></pre></td></tr></table></figure>
<p>作为评价标准，我们常常使用<strong>准确率</strong>，它描述了我们预测正确的得分。请注意以后我们实现的所有分类器都需要有这个API：<strong>train(X, y)</strong>函数。该函数使用训练集的数据和标签来进行训练。从其内部来看，类应该实现一些关于标签和标签如何被预测的模型。这里还有个<strong>predict(X)</strong>函数，它的作用是预测输入的新数据的分类标签。现在还没介绍分类器的实现，下面就是使用L1距离的Nearest Neighbor分类器的实现套路：  </p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">    <span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">​    </span><br><span class="line">​    <span class="keyword">class</span> <span class="title class_">NearestNeighbor</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">​      <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">​        <span class="keyword">pass</span></span><br><span class="line">​    </span><br><span class="line">      <span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">self, X, y</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot; X is N x D where each row is an example. Y is 1-dimension of size N &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># the nearest neighbor classifier simply remembers all the training data</span></span><br><span class="line">        self.Xtr = X</span><br><span class="line">        self.ytr = y</span><br><span class="line">    </span><br><span class="line">      <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self, X</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot; X is N x D where each row is an example we wish to predict label for &quot;&quot;&quot;</span></span><br><span class="line">        num_test = X.shape[<span class="number">0</span>]</span><br><span class="line">        <span class="comment"># lets make sure that the output type matches the input type</span></span><br><span class="line">        Ypred = np.zeros(num_test, dtype = self.ytr.dtype)</span><br><span class="line">    </span><br><span class="line">        <span class="comment"># loop over all test rows</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> xrange(num_test):</span><br><span class="line">          <span class="comment"># find the nearest training image to the i&#x27;th test image</span></span><br><span class="line">          <span class="comment"># using the L1 distance (sum of absolute value differences)</span></span><br><span class="line">          distances = np.<span class="built_in">sum</span>(np.<span class="built_in">abs</span>(self.Xtr - X[i,:]), axis = <span class="number">1</span>)</span><br><span class="line">          min_index = np.argmin(distances) <span class="comment"># get the index with smallest distance</span></span><br><span class="line">          Ypred[i] = self.ytr[min_index] <span class="comment"># predict the label of the nearest example</span></span><br><span class="line">    </span><br><span class="line">        <span class="keyword">return</span> Ypred</span><br></pre></td></tr></table></figure>
<p>如果你用这段代码跑CIFAR-10，你会发现准确率能达到<strong>38.6%</strong>。这比随机猜测的10%要好，但是比人类识别的水平（据研究推测是94%）和卷积神经网络能达到的95%还是差多了。</p>
<p><strong>距离选择</strong>：计算向量间的距离有很多种方法，另一个常用的方法是<strong>L2距离</strong>，从几何学的角度，可以理解为它在计算两个向量间的欧式距离。L2距离的公式如下：  </p>
<p>$displaystyle d_2(I_1,I_2)=sqrt{ sum_p(I^p_1-I^p_2)^2}$</p>
<img src="/2024/05/06/14-24-17/60.jpg" class>
<p>换句话说，我们依旧是在计算像素间的差值，只是先求其平方，然后把这些平方全部加起来，最后对这个和开方。在Numpy中，我们只需要替换上面代码中的1行代码就行：  </p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">distances = np.sqrt(np.<span class="built_in">sum</span>(np.square(self.Xtr - X[i,:]), axis = <span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<p>注意在这里使用了<strong>np.sqrt</strong>，但是在实际中可能不用。因为求平方根函数是一个单调函数，它对不同距离的绝对值求平方根虽然改变了数值大小，但依然保持了不同距离大小的顺序。所以用不用它，都能够对像素差异的大小进行正确比较。如果你在CIFAR-10上面跑这个模型，正确率是<strong>35.4%</strong>，比刚才低了一点。</p>
<p><strong>L1和L2比较</strong>。比较这两个度量方式是挺有意思的。在面对两个向量之间的差异时，L2比L1更加不能容忍这些差异。也就是说，相对于1个巨大的差异，L2距离更倾向于接受多个中等程度的差异。L1和L2都是在<a target="_blank" rel="noopener" href="https://planetmath.org/vectorpnorm">p-norm__</a>常用的特殊形式。</p>
<img src="/2024/05/06/14-24-17/60.jpg" class>
<h2 id="k-Nearest-Neighbor分类器"><a href="#k-Nearest-Neighbor分类器" class="headerlink" title="k-Nearest Neighbor分类器"></a>k-Nearest Neighbor分类器</h2><p>你可能注意到了，为什么只用最相似的1张图片的标签来作为测试图像的标签呢？这不是很奇怪吗！是的，使用<strong>k-Nearest Neighbor分类器</strong>就能做得更好。它的思想很简单：与其只找最相近的那1个图片的标签，我们找最相似的k个图片的标签，然后让他们针对测试图片进行投票，最后把票数最高的标签作为对测试图片的预测。所以当k=1的时候，k-Nearest Neighbor分类器就是Nearest Neighbor分类器。从直观感受上就可以看到，更高的k值可以让分类的效果更平滑，使得分类器对于异常值更有抵抗力。  </p>
<img src="/2024/05/06/14-24-17/237615075-bdd1fa05-cb3c-4dc5-b24f-940987cdb225.jpg" class>
<p>上面示例展示了Nearest Neighbor分类器和5-Nearest Neighbor分类器的区别。例子使用了2维的点来表示，分成3类（红、蓝和绿）。不同颜色区域代表的是使用L2距离的分类器的<strong>决策边界</strong>。白色的区域是分类模糊的例子（即图像与两个以上的分类标签绑定）。需要注意的是，在NN分类器中，异常的数据点（比如：在蓝色区域中的绿点）制造出一个不正确预测的孤岛。5-NN分类器将这些不规则都平滑了，使得它针对测试数据的<strong>泛化（generalization）</strong>能力更好（例子中未展示）。注意，5-NN中也存在一些灰色区域，这些区域是因为近邻标签的最高票数相同导致的（比如：2个邻居是红色，2个邻居是蓝色，还有1个是绿色)。</p>
<p>在实际中，大多使用k-NN分类器。但是k值如何确定呢？接下来就讨论这个问题。  </p>
<h2 id="用于超参数调优的验证集"><a href="#用于超参数调优的验证集" class="headerlink" title="用于超参数调优的验证集"></a>用于超参数调优的验证集</h2><p>k-NN分类器需要设定k值，那么选择哪个k值最合适的呢？我们可以选择不同的距离函数，比如L1范数和L2范数等，那么选哪个好？还有不少选择我们甚至连考虑都没有考虑到（比如：点积）。所有这些选择，被称为<strong>超参数（hyperparameter）</strong>。在基于数据进行学习的机器学习算法设计中，超参数是很常见的。一般说来，这些超参数具体怎么设置或取值并不是显而易见的。</p>
<p>你可能会建议尝试不同的值，看哪个值表现最好就选哪个。好主意！我们就是这么做的，但这样做的时候要非常细心。特别注意：<strong>决不能使用测试集来进行调优</strong>。当你在设计机器学习算法的时候，应该把测试集看做非常珍贵的资源，不到最后一步，绝不使用它。如果你使用测试集来调优，而且算法看起来效果不错，那么真正的危险在于：算法实际部署后，性能可能会远低于预期。这种情况，称之为算法对测试集<strong>过拟合</strong>。从另一个角度来说，如果使用测试集来调优，实际上就是把测试集当做训练集，由测试集训练出来的算法再跑测试集，自然性能看起来会很好。这其实是过于乐观了，实际部署起来效果就会差很多。所以，最终测试的时候再使用测试集，可以很好地近似度量你所设计的分类器的泛化性能（在接下来的课程中会有很多关于泛化性能的讨论）。</p>
<p>&gt; 测试数据集只使用一次，即在训练完成后评价最终的模型时使用。</p>
<p>但是只有训练集和测试集会有一个问题，那就是不知道算法在新数据上表现如何。 </p>
<p>好在我们有不用测试集调优的方法。其思路是：从训练集中取出一部分数据用来调优，我们称之为<strong>验证集（validation set）</strong>。以CIFAR-10为例，我们可以用49000个图像作为训练集，用1000个图像作为验证集。验证集其实就是作为假的测试集来调优。下面就是代码：</p>
<p>​<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment"># assume we have Xtr_rows, Ytr, Xte_rows, Yte as before</span></span><br><span class="line"><span class="comment"># recall Xtr_rows is 50,000 x 3072 matrix</span></span><br><span class="line">Xval_rows = Xtr_rows[:<span class="number">1000</span>, :] <span class="comment"># take first 1000 for validation</span></span><br><span class="line">Yval = Ytr[:<span class="number">1000</span>]</span><br><span class="line">Xtr_rows = Xtr_rows[<span class="number">1000</span>:, :] <span class="comment"># keep last 49,000 for train</span></span><br><span class="line">Ytr = Ytr[<span class="number">1000</span>:]</span><br><span class="line"></span><br><span class="line"><span class="comment"># find hyperparameters that work best on the validation set</span></span><br><span class="line">validation_accuracies = []</span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> [<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">10</span>, <span class="number">20</span>, <span class="number">50</span>, <span class="number">100</span>]:</span><br><span class="line"></span><br><span class="line">  <span class="comment"># use a particular value of k and evaluation on validation data</span></span><br><span class="line">  nn = NearestNeighbor()</span><br><span class="line">  nn.train(Xtr_rows, Ytr)</span><br><span class="line">  <span class="comment"># here we assume a modified NearestNeighbor class that can take a k as input</span></span><br><span class="line">  Yval_predict = nn.predict(Xval_rows, k = k)</span><br><span class="line">  acc = np.mean(Yval_predict == Yval)</span><br><span class="line">  <span class="built_in">print</span> <span class="string">&#x27;accuracy: %f&#x27;</span> % (acc,)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># keep track of what works on the validation set</span></span><br><span class="line">  validation_accuracies.append((k, acc))</span><br><span class="line"></span><br></pre></td></tr></table></figure></p>
<p>程序结束后，我们会作图分析出哪个k值表现最好，然后用这个k值来跑真正的测试集，并作出对算法的评价。  </p>
<p>&gt; 把训练集分成训练集和验证集。使用验证集来对所有超参数调优。最后只在测试集上跑一次并报告结果。</p>
<p><strong>交叉验证</strong>。有时候，训练集数量较小（因此验证集的数量更小），人们会使用一种被称为<strong>交叉验证</strong>的方法，这种方法更加复杂些。还是用刚才的例子，如果是交叉验证集，我们就不是取1000个图像，而是将训练集平均分成5份，其中4份用来训练，1份用来验证。然后我们循环着取其中4份来训练，其中1份来验证，最后取所有5次验证结果的平均值作为算法验证结果。</p>
<img src="/2024/05/06/14-24-17/6a3ceec60cc0a379b4939c37ee3e89e8_b.png" class>
<p>这就是5份交叉验证对k值调优的例子。针对每个k值，得到5个准确率结果，取其平均值，然后对不同k值的平均表现画线连接。本例中，当k=7的时算法表现最好（对应图中的准确率峰值）。如果我们将训练集分成更多份数，直线一般会更加平滑（噪音更少）。</p>
<p><strong>实际应用</strong>。在实际情况下，人们不是很喜欢用交叉验证，主要是因为它会耗费较多的计算资源。一般直接把训练集按照50%-90%的比例分成训练集和验证集。但这也是根据具体情况来定的：如果超参数数量多，你可能就想用更大的验证集，而验证集的数量不够，那么最好还是用交叉验证吧。至于分成几份比较好，一般都是分成3、5和10份。  </p>
<img src="/2024/05/06/14-24-17/cc88207c6c3c5e91df8b6367368f6450_b.jpg" class>
<p>常用的数据分割模式。给出训练集和测试集后，训练集一般会被均分。这里是分成5份。前面4份用来训练，黄色那份用作验证集调优。如果采取交叉验证，那就各份轮流作为验证集。最后模型训练完毕，超参数都定好了，让模型跑一次（而且只跑一次）测试集，以此测试结果评价算法。</p>
<h2 id="Nearest-Neighbor分类器的优劣"><a href="#Nearest-Neighbor分类器的优劣" class="headerlink" title="Nearest Neighbor分类器的优劣"></a>Nearest Neighbor分类器的优劣</h2><p>现在对Nearest Neighbor分类器的优缺点进行思考。首先，Nearest Neighbor分类器易于理解，实现简单。其次，算法的训练不需要花时间，因为其训练过程只是将训练集数据存储起来。然而测试要花费大量时间计算，因为每个测试图像需要和所有存储的训练图像进行比较，这显然是一个缺点。在实际应用中，我们关注测试效率远远高于训练效率。其实，我们后续要学习的卷积神经网络在这个权衡上走到了另一个极端：虽然训练花费很多时间，但是一旦训练完成，对新的测试数据进行分类非常快。这样的模式就符合实际使用需求。</p>
<p>Nearest Neighbor分类器的计算复杂度研究是一个活跃的研究领域，若干<strong>Approximate Nearest Neighbor </strong>(ANN)算法和库的使用可以提升Nearest Neighbor分类器在数据上的计算速度(比如：FLANN)。这些算法可以在准确率和时空复杂度之间进行权衡，并通常依赖一个预处理/索引过程，这个过程中一般包含kd树的创建和k-means算法的运用。</p>
<p>Nearest Neighbor分类器在某些特定情况（比如数据维度较低）下，可能是不错的选择。但是在实际的图像分类工作中，很少使用。因为图像都是高维度数据（他们通常包含很多像素），而高维度向量之间的距离通常是反直觉的。下面的图片展示了基于像素的相似和基于感官的相似是有很大不同的：</p>
<img src="/2024/05/06/14-24-17/fd42d369eebdc5d81c89593ec1082e32_b.png" class>
<p>在高维度数据上，基于像素的的距离和感官上的非常不同。上图中，右边3张图片和左边第1张原始图片的L2距离是一样的。很显然，基于像素比较的相似和感官上以及语义上的相似是不同的。  </p>
<p>这里还有个视觉化证据，可以证明使用像素差异来比较图像是不够的。这是一个叫做t-SNE的可视化技术，它将CIFAR-10中的图片按照二维方式排布，这样能很好展示图片之间的像素差异值。在这张图片中，排列相邻的图片L2距离就小。  </p>
<img src="/2024/05/06/14-24-17/0f4980edb8710eaba0f3e661b1cbb830_b.jpg" class>
<p>上图使用t-SNE的可视化技术将CIFAR-10的图片进行了二维排列。排列相近的图片L2距离小。可以看出，图片的排列是被背景主导而不是图片语义内容本身主导。  </p>
<p>具体说来，这些图片的排布更像是一种颜色分布函数，或者说是基于背景的，而不是图片的语义主体。比如，狗的图片可能和青蛙的图片非常接近，这是因为两张图片都是白色背景。从理想效果上来说，我们肯定是希望同类的图片能够聚集在一起，而不被背景或其他不相关因素干扰。为了达到这个目的，我们不能止步于原始像素比较，得继续前进。</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>简要说来：</p>
<ul>
<li>介绍了<strong>图像分类</strong>问题。在该问题中，给出一个由被标注了分类标签的图像组成的集合，要求算法能预测没有标签的图像的分类标签，并根据算法预测准确率进行评价。</li>
<li>介绍了一个简单的图像分类器：<strong>最近邻分类器(Nearest Neighbor classifier)</strong>。分类器中存在不同的超参数(比如k值或距离类型的选取)，要想选取好的超参数不是一件轻而易举的事。</li>
<li>选取超参数的正确方法是：将原始训练集分为训练集和<strong>验证集</strong>，我们在验证集上尝试不同的超参数，最后保留表现最好那个。</li>
<li>如果训练数据量不够，使用<strong>交叉验证</strong>方法，它能帮助我们在选取最优超参数的时候减少噪音。</li>
<li>一旦找到最优的超参数，就让算法以该参数在测试集跑且只跑一次，并根据测试结果评价算法。</li>
<li>最近邻分类器能够在CIFAR-10上得到将近40%的准确率。该算法简单易实现，但需要存储所有训练数据，并且在测试的时候过于耗费计算能力。</li>
<li>最后，我们知道了仅仅使用L1和L2范数来进行像素比较是不够的，图像更多的是按照背景和颜色被分类，而不是语义主体分身。</li>
</ul>
<p>在接下来的课程中，我们将专注于解决这些问题和挑战，并最终能够得到超过90%准确率的解决方案。该方案能够在完成学习就丢掉训练集，并在一毫秒之内就完成一张图片的分类。</p>
<h2 id="小结：实际应用k-NN"><a href="#小结：实际应用k-NN" class="headerlink" title="小结：实际应用k-NN"></a>小结：实际应用k-NN</h2><p>如果你希望将k-NN分类器用到实处（最好别用到图像上，若是仅仅作为练手还可以接受），那么可以按照以下流程：</p>
<ol>
<li>预处理你的数据：对你数据中的特征进行归一化（normalize），让其具有零平均值（zero mean）和单位方差（unit variance）。在后面的小节我们会讨论这些细节。本小节不讨论，是因为图像中的像素都是同质的，不会表现出较大的差异分布，也就不需要标准化处理了。</li>
<li>如果数据是高维数据，考虑使用降维方法，比如PCA或随机投影。</li>
<li>将数据随机分入训练集和验证集。按照一般规律，70%-90% 数据作为训练集。这个比例根据算法中有多少超参数，以及这些超参数对于算法的预期影响来决定。如果需要预测的超参数很多，那么就应该使用更大的验证集来有效地估计它们。如果担心验证集数量不够，那么就尝试交叉验证方法。如果计算资源足够，使用交叉验证总是更加安全的（份数越多，效果越好，也更耗费计算资源）。</li>
<li>在验证集上调优，尝试足够多的k值，尝试L1和L2两种范数计算方式。</li>
<li>如果分类器跑得太慢，尝试使用Approximate Nearest Neighbor库（比如FLANN）来加速这个过程，其代价是降低一些准确率。</li>
<li>对最优的超参数做记录。记录最优参数后，是否应该让使用最优参数的算法在完整的训练集上运行并再次训练呢？因为如果把验证集重新放回到训练集中（自然训练集的数据量就又变大了），有可能最优参数又会有所变化。在实践中，<strong>不要这样做</strong>。千万不要在最终的分类器中使用验证集数据，这样做会破坏对于最优参数的估计。<strong>直接使用测试集来测试用最优参数设置好的最优模型</strong>，得到测试集数据的分类准确率，并以此作为你的kNN分类器在该数据上的性能表现。</li>
</ol>
<h1 id="数据集代码实现"><a href="#数据集代码实现" class="headerlink" title="数据集代码实现"></a>数据集代码实现</h1><p>我们这里介绍了一系列的数据集和验证集的概念，但是我们肯定不会手动去进行计算和验证，必须依靠计算机来实现，所以我们应该如何使用代码去准备一个数据集呢？这就需要靠一些框架来完成这个操作</p>
<p>大家在算数的时候，会使用计算器来加快计算过程，在这里计算器只是一个工具，核心是你怎么去计算和要计算什么，在深度学习中也是，代码和相关的框架只不过是工具，可以起到计算器的作用，让你免于手动计算和自己搭建代码的困境，使你可以快速完成模型的学习</p>
<p>目前常用的深度学习框架是PyTorch、TensorFlow等，在学术界，PyTorch是主流的框架，而且简单易学，我们在这里使用PyTorch来完成一系列深度学习的代码任务</p>
<h2 id="数据集类——Dataset"><a href="#数据集类——Dataset" class="headerlink" title="数据集类——Dataset"></a>数据集类——Dataset</h2><p>在PyTorch中，Dataset是一个抽象的数据集类，可以用来自定义一些数据集类，用来实现从磁盘中读取数据集、读取标签和样本等操作，借助pytorch中dataset类，你可以创建适应任意模型的数据集接口</p>
<p>所谓数据集，无非就是一组{x:y}的集合吗，你只需要在这个类里说明“有一组{x:y}的集合”就可以了。x是样本的数据内容，y是样本标签</p>
<p>对于图像分类任务，图像+分类</p>
<p>对于目标检测任务，图像+bbox、分类</p>
<p>对于超分辨率任务，低分辨率图像+超分辨率图像</p>
<p>对于文本分类任务，文本+分类</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Dataset</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;An abstract class representing a Dataset.</span></span><br><span class="line"><span class="string">    All other datasets should subclass it. All subclasses should override</span></span><br><span class="line"><span class="string">    ``__len__``, that provides the size of the dataset, and ``__getitem__``,</span></span><br><span class="line"><span class="string">    supporting integer indexing in range from 0 to len(self) exclusive.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"> </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line">        <span class="keyword">raise</span> NotImplementedError</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">raise</span> NotImplementedError</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__add__</span>(<span class="params">self, other</span>):</span><br><span class="line">        <span class="keyword">return</span> ConcatDataset([self, other])</span><br></pre></td></tr></table></figure>
<p>上面的代码是pytorch给出的官方代码，其中__getitem__和__len__是子类必须继承的，或者说pytorch给出的官方代码限制了标准，你要按照它的标准进行数据集建立，其中__getitem__函数就是获取样本对（内容+标签），__len__就是获取数据集大小（或者说长度、样本数量）</p>
<p>比如说，我有一个图像分类的数据集，我想训练一个分类器，那么我就可以构建一个这样的数据集，它只需要满足下面的条件</p>
<ol>
<li>可以通过序号，得到图片和对应的分类标签</li>
<li>可以知道图片的数量（也就是数据集大小，从0开始计数）</li>
</ol>
<p>只要满足这两个条件，那么这个类就可以实例化为一个符合要求的数据集对象</p>
<p>我们考虑一个实际情况，图像分类的数据集放在文件夹D中，有三个类别的样本，分别在D下的a、b、c三个子文件夹中，子文件夹的名称就是类别的名称，那么我们如何自制一个数据集类来读取呢？</p>
<p>首先我们要告诉程序，数据集在哪里（或者说告诉路径），然后说明要对数据做什么变换，明确这是训练数据集还是验证数据集等等，所以我们需要在__init__函数中读取这些</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset</span><br><span class="line"> </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyDataSet</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, image_dir, dataset_type, transform=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        image_dir: 路径</span></span><br><span class="line"><span class="string">        dataset_type: [&#x27;train&#x27;, &#x27;test&#x27;]</span></span><br><span class="line"><span class="string">        transform：各种处理</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line"> </span><br><span class="line">        self.dataset_path = image_dir</span><br><span class="line">        self.transform = transform</span><br><span class="line">        self.dataset_type = dataset_type</span><br><span class="line">        self.class_name=[]</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> img_dir,class_name,_ <span class="keyword">in</span> os.walk(self.dataset_path) :</span><br><span class="line">            self.class_name.append(class_name)</span><br><span class="line">        lines = f.readlines()</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> lines:</span><br><span class="line">            self.sample_list.append(line.strip())</span><br><span class="line">        f.close()</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line">        item = self.sample_list[index]</span><br><span class="line">        <span class="comment"># img = cv2.imread(item.split(&#x27; _&#x27;)[0])</span></span><br><span class="line">        img = Image.<span class="built_in">open</span>(item.split(<span class="string">&#x27; _&#x27;</span>)[<span class="number">0</span>])</span><br><span class="line">        <span class="keyword">if</span> self.transform <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            img = self.transform(img)</span><br><span class="line">        label = <span class="built_in">int</span>(item.split(<span class="string">&#x27; _&#x27;</span>)[-<span class="number">1</span>])</span><br><span class="line">        <span class="keyword">return</span> img, label</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.sample_list)</span><br></pre></td></tr></table></figure>
<h2 id="拓展阅读"><a href="#拓展阅读" class="headerlink" title="拓展阅读"></a>拓展阅读</h2><p>下面是一些你可能感兴趣的拓展阅读链接：</p>
<ul>
<li><a target="_blank" rel="noopener" href="http://homes.cs.washington.edu/%7Epedrod/papers/cacm12.pdf">A Few Useful Things to Know about Machine Learning__</a>，文中第6节与本节相关，但是整篇文章都强烈推荐。  </li>
<li><a target="_blank" rel="noopener" href="http://people.csail.mit.edu/torralba/shortCourseRLOC/index.html">Recognizing and Learning Object Categories__</a>，ICCV 2005上的一节关于物体分类的课程。  </li>
</ul>

    </div>

    
    
    

    <footer class="post-footer">
          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>本文作者： </strong>yao
  </li>
  <li class="post-copyright-link">
      <strong>本文链接：</strong>
      <a href="https://pkunicor.github.io/2024/05/06/14-24-17/" title="计算机视觉 图像分类">https://pkunicor.github.io/2024/05/06/14-24-17/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

          <div class="post-tags">
              <a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="tag"># 计算机视觉, 图像处理, 深度学习</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2024/05/06/10-28-51/" rel="prev" title="eecs498 ML-DL-CV 笔记汇总">
                  <i class="fa fa-chevron-left"></i> eecs498 ML-DL-CV 笔记汇总
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2024/05/06/15-22-39/" rel="next" title="计算机视觉 线性分类器">
                  计算机视觉 线性分类器 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    <div class="comments gitalk-container"></div>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">yao</span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/mist/" rel="noopener" target="_blank">NexT.Mist</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>





  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","mhchem":true,"js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>


<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/gitalk/1.8.0/gitalk.css" integrity="sha256-AJnUHL7dBv6PGaeyPQJcgQPDjt/Hn/PvYZde1iqfp8U=" crossorigin="anonymous">

<script class="next-config" data-name="gitalk" type="application/json">{"enable":true,"github_id":"PKunicor","repo":"PKunicor.github.io","client_id":"2efe0e153686e5d9e67d","client_secret":"c84e031b6ac86ce366a6b61640a4b1a8e01d05e0","admin_user":"PKunicor","distraction_free_mode":true,"proxy":"https://cors-anywhere.azm.workers.dev/https://github.com/login/oauth/access_token","language":"zh-CN","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/gitalk/1.8.0/gitalk.min.js","integrity":"sha256-MVK9MGD/XJaGyIghSVrONSnoXoGh3IFxLw0zfvzpxR4="},"path_md5":"84d82d3d98d3e40f77ec9853ed5697d9"}</script>
<script src="/js/third-party/comments/gitalk.js"></script>

</body>
</html>
